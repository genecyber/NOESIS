"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[538],{3910:(e,s,t)=>{t.d(s,{$Ld:()=>ag,$Mx:()=>tz,$P2:()=>tw,$TP:()=>ik,$o$:()=>ny,$ph:()=>af,A4X:()=>ac,AVh:()=>iP,Aib:()=>er,AyL:()=>at,BRf:()=>ii,Bl1:()=>t7,C2_:()=>nr,CAk:()=>sY,CBj:()=>eN,CF0:()=>et,C_m:()=>ej,Cb2:()=>s1,CbL:()=>nF,Ccq:()=>z,Ct0:()=>ab,D$4:()=>eQ,DDe:()=>tU,DIv:()=>D,DbD:()=>s9,Dji:()=>tQ,Dki:()=>n_,E6D:()=>aP,E9I:()=>T,EAC:()=>sG,EKW:()=>tX,ELH:()=>e2,EPI:()=>t6,E_G:()=>sJ,Eh_:()=>ae,F05:()=>sn,F75:()=>tN,FEt:()=>aa,FIB:()=>sK,FJW:()=>iF,FSH:()=>U,Fbv:()=>tK,FmT:()=>nB,FoX:()=>nd,FqW:()=>s6,FuQ:()=>s0,Fzc:()=>t1,G2X:()=>eZ,G3L:()=>nE,GEu:()=>sj,GNt:()=>nW,GXK:()=>sv,Giz:()=>ne,HMe:()=>iS,HT0:()=>nO,HaQ:()=>t2,Hff:()=>aw,Hi6:()=>eJ,Hvf:()=>sd,I04:()=>aA,IVZ:()=>ax,IWp:()=>tG,IeB:()=>nv,Ilc:()=>ek,Ilk:()=>Y,IrO:()=>sp,IzE:()=>nR,JFO:()=>tJ,JGb:()=>s_,JP3:()=>ih,J_N:()=>eI,KJ:()=>av,KcC:()=>e9,Kul:()=>no,L1Z:()=>tp,L3d:()=>eh,LGm:()=>tv,LJl:()=>tF,LN6:()=>an,LdY:()=>ed,LlQ:()=>nS,LqK:()=>e7,MH$:()=>sa,MOY:()=>io,MRG:()=>sB,MRX:()=>O,MYn:()=>t$,MgS:()=>sx,Mjg:()=>eV,Mt5:()=>so,N2L:()=>s$,NDb:()=>eF,NJd:()=>nf,NlK:()=>eG,Nmr:()=>ey,Nyc:()=>en,O0k:()=>sI,OBR:()=>nk,OK_:()=>sA,OOL:()=>eR,P3b:()=>tx,PBg:()=>s2,PRX:()=>ak,PV9:()=>s7,P_g:()=>n0,Paj:()=>j,Pgx:()=>sl,Plw:()=>ib,Pqo:()=>ai,PyP:()=>iN,Pyv:()=>n8,Pzh:()=>sk,QGw:()=>eT,QJ0:()=>sP,QNG:()=>iC,QRP:()=>ez,Qs9:()=>eM,RIx:()=>sg,RWH:()=>eW,Rcj:()=>e6,RvM:()=>tl,S7g:()=>el,S9m:()=>eo,SIh:()=>aE,SNK:()=>al,SPn:()=>ee,SX4:()=>tn,Shx:()=>ta,Sm3:()=>sh,SzV:()=>es,TUv:()=>ia,Tc6:()=>V,Tk_:()=>tA,TrS:()=>nt,U14:()=>aF,UNt:()=>sr,URg:()=>nA,UX7:()=>sR,U_I:()=>nT,UaF:()=>aq,UqB:()=>nQ,V2z:()=>th,V9g:()=>il,VD9:()=>tb,VG4:()=>ns,VT:()=>nN,VkI:()=>tg,Vkl:()=>iO,Vnd:()=>sM,VoY:()=>G,Vx0:()=>J,W5i:()=>nU,W6E:()=>ic,W7k:()=>nD,WIq:()=>nH,WJS:()=>tY,X0l:()=>tc,X6D:()=>aD,XBq:()=>s5,XWm:()=>sH,XfN:()=>em,Xi0:()=>R,Xrw:()=>nP,Xsl:()=>W,Xvs:()=>ts,Xyp:()=>n9,Y2A:()=>q,YHO:()=>nc,YR3:()=>si,YVy:()=>eA,YZs:()=>sc,Yd3:()=>ig,YjU:()=>aL,YqH:()=>iT,YyD:()=>nG,Z0G:()=>iq,Z83:()=>sX,Z9R:()=>tB,ZGD:()=>tT,ZIt:()=>ir,ZM0:()=>tH,Zip:()=>eu,_Dc:()=>sS,_TZ:()=>iy,_yz:()=>eg,aGV:()=>nj,aHU:()=>sN,aLA:()=>aB,aN4:()=>nx,adp:()=>tt,ag_:()=>as,ajg:()=>nL,b9b:()=>t5,bFh:()=>s8,bGU:()=>nZ,bOZ:()=>ti,bZR:()=>nI,bmk:()=>I,bpB:()=>sw,c$o:()=>nl,c93:()=>ni,cD:()=>sF,cR9:()=>sQ,cXP:()=>t4,cl7:()=>n1,cpF:()=>ev,crA:()=>nn,crd:()=>eK,ct5:()=>n$,czX:()=>sT,d7$:()=>sC,d8n:()=>t9,dAU:()=>e5,dBN:()=>aC,dMI:()=>nz,db0:()=>iu,dg9:()=>tf,diq:()=>am,dp7:()=>nX,dt5:()=>iA,eQ7:()=>ad,eu8:()=>X,f7H:()=>t_,fCQ:()=>np,fGl:()=>nJ,fX1:()=>nq,fjb:()=>ap,fl$:()=>t8,fqH:()=>ao,g$7:()=>aS,gEj:()=>ei,gJd:()=>sW,gSt:()=>sO,gqD:()=>iw,gqe:()=>n5,gxi:()=>tL,h0m:()=>ec,hFk:()=>tr,hNN:()=>tO,h_s:()=>tC,hbt:()=>ss,hf2:()=>iD,i3J:()=>nV,iGD:()=>eD,iKv:()=>e0,j2j:()=>nm,j6y:()=>e1,j7p:()=>s4,j9c:()=>tZ,jJ4:()=>Q,jQR:()=>it,jWM:()=>td,jZD:()=>tu,jZx:()=>tk,j_7:()=>e3,jbx:()=>tm,jlM:()=>tj,jt4:()=>nh,kPE:()=>se,klo:()=>sL,l2J:()=>te,lHM:()=>sU,lX9:()=>E,lf8:()=>nw,lr8:()=>eb,ltw:()=>nY,m1H:()=>tE,m68:()=>iM,mjH:()=>nC,mp$:()=>iI,muz:()=>aT,mvc:()=>tq,nD1:()=>eq,nDC:()=>eE,nII:()=>nM,nR6:()=>ah,nuw:()=>iv,o2t:()=>N,o57:()=>sD,oJL:()=>ar,oKc:()=>tR,oO_:()=>n3,oZ3:()=>aM,oaf:()=>tW,pBZ:()=>tD,pHg:()=>ng,pJ8:()=>sE,pSU:()=>eP,pW7:()=>ex,qBz:()=>tI,qCM:()=>ix,qLW:()=>sV,qQb:()=>n4,qWZ:()=>ay,qcZ:()=>na,qtL:()=>iB,qvY:()=>eU,rKH:()=>is,rSR:()=>B,rZ_:()=>tM,rb:()=>eX,riX:()=>to,s8j:()=>nb,sKA:()=>iE,sbd:()=>sy,sns:()=>$,t8g:()=>eB,tAq:()=>s3,tDL:()=>su,tKX:()=>sf,tU7:()=>tV,tUF:()=>sZ,tm_:()=>e4,uA4:()=>au,uKS:()=>a_,uwI:()=>eL,v11:()=>sb,vGK:()=>sq,vTA:()=>im,vTy:()=>ew,vZB:()=>eO,vdi:()=>nu,vf1:()=>t3,vgU:()=>tP,vh2:()=>ea,vnq:()=>n6,vqx:()=>st,w0O:()=>iL,w4W:()=>ep,wXv:()=>e8,wZy:()=>sm,wc1:()=>e_,wju:()=>id,wrZ:()=>ip,x5Z:()=>n2,xI8:()=>nK,xNh:()=>ef,xbg:()=>t0,xfe:()=>eY,xpG:()=>eC,y5s:()=>K,yGT:()=>i_,y_I:()=>Z,yaC:()=>sz,yuQ:()=>eS,z1x:()=>H,z45:()=>eH,zEN:()=>tS,zPm:()=>ty,zml:()=>e$,zys:()=>n7});var n=t(8747),a=t(3089),i=t(7633),o=t(6412),r=t(1255),l=t(777),c=t(2510);let{InferenceSession:d,Tensor:_,env:u}=l.M,h={EncoderOnly:0,EncoderDecoder:1,Seq2Seq:2,Vision2Seq:3,DecoderOnly:4,MaskGeneration:5},m=new Map,p=new Map,g=new Map;async function f(e,s,t){let n=`onnx/${s}${t.quantized?"_quantized":""}.onnx`,a=await (0,i.Yw)(e,n,!0,t);try{return await d.create(a,{executionProviders:l.t})}catch(e){if(1===l.t.length&&"wasm"===l.t[0])throw e;return console.warn(e),console.warn("Something went wrong during model construction (most likely a missing operation). Using `wasm` as a fallback. "),await d.create(a,{executionProviders:["wasm"]})}}async function w(e,s){let t=function(e,s){let t=Object.create(null),n=[];for(let a of e.inputNames){let e=s[a];if(!(e instanceof r.qY)){n.push(a);continue}t[a]=u.wasm.proxy?e.clone():e}if(n.length>0)throw Error(`An error occurred during model execution: "Missing the following inputs: ${n.join(", ")}.`);let a=Object.keys(s).length,i=e.inputNames.length;if(a>i){let t=Object.keys(s).filter(s=>!e.inputNames.includes(s));console.warn(`WARNING: Too many inputs were provided (${a} > ${i}). The following inputs will be ignored: "${t.join(", ")}".`)}return t}(e,s);try{let s=await e.run(t);return s=function e(s){for(let t in s)s[t]instanceof _?s[t]=new r.qY(s[t]):"object"==typeof s[t]&&e(s[t]);return s}(s)}catch(e){throw console.error(`An error occurred during model execution: "${e}".`),console.error("Inputs given to model:",t),e}}function x(e,s){let t=e.config.pad_token_id??null,n=e.config.eos_token_id??null;(0,a.k1)(n)&&(n=[n]);let i=-1!==s.indexOf(t),o=null===n||!n.includes(t);if(!i||!o)return(0,r.oC)(s);{let e=BigInt64Array.from(s.data.map(e=>e!=t));return new r.qY("int64",e,s.dims)}}function y(e,s,t){if(!e.inputNames.includes("position_ids"))return;let n=new BigInt64Array(s.attention_mask.data.length);for(let e=0;e<s.attention_mask.dims[0];++e){let t=e*s.attention_mask.dims[1],a=BigInt(0);for(let e=0;e<s.attention_mask.dims[1];++e){let i=t+e;0n===s.attention_mask.data[i]?n[i]=BigInt(1):(n[i]=a,a+=s.attention_mask.data[i])}}s.position_ids=new r.qY("int64",n,s.attention_mask.dims),t&&(s.position_ids=s.position_ids.slice(null,-1).unsqueeze_(-1))}function M(e){return new r.qY("bool",[e],[1])}async function k(e,s){let{encoder_outputs:t,past_key_values:n}=s;t||(t=(await F(e,s)).last_hidden_state);let a={input_ids:s.decoder_input_ids,encoder_hidden_states:t},i=!!n;e.decoder_merged_session.inputNames.includes("use_cache_branch")&&(a.use_cache_branch=M(i)),e.decoder_merged_session.inputNames.includes("encoder_attention_mask")&&(a.encoder_attention_mask=s.attention_mask),y(e.decoder_merged_session,a,i),e.addPastKeyValues(a,n);let o=await w(e.decoder_merged_session,a);return new iA({logits:o.logits,past_key_values:n=e.getPastKeyValues(o,n),encoder_outputs:t,...e.getAttentions(o)})}function b(e,s,t,n){let a=[],i=0,o=e.requires_attention_mask??!0,l=t.decoder_input_ids??t.decoder_start_token_id??t.bos_token_id??t.eos_token_id;for(let t of(l instanceof r.qY?l=l.tolist().flat():Array.isArray(l)||(l=[l]),s)){t.dims=[1,...t.dims];let s={inputs:t,encoder_outputs:null,prev_model_outputs:null,output_token_ids:l,done:!1,score:0,id:i++};o&&(s.attention_mask=x(e,t)),a.push(s)}return a}async function v(e,s){let t=e.main_input_name,n=s.output_token_ids;s.prev_model_outputs&&(n=n.slice(-1));let a={[t]:s.inputs,decoder_input_ids:function(e){if(e instanceof r.qY)return e;if(0===e.length)throw Error("items must be non-empty");if(!Array.isArray(e[0]))return new r.qY("int64",BigInt64Array.from(e.map(e=>BigInt(e))),[1,e.length]);if(e.some(s=>s.length!==e[0].length))throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' and/or 'truncation=True' to have batched tensors with the same length.");return new r.qY("int64",BigInt64Array.from(e.flat().map(e=>BigInt(e))),[e.length,e[0].length])}(n),encoder_outputs:s.encoder_outputs,past_key_values:s.prev_model_outputs?.past_key_values};s.attention_mask&&(a.attention_mask=s.attention_mask);let i=await e.forward(a);return s.prev_model_outputs=i,s.encoder_outputs=i.encoder_outputs,i}function S(e,s){e.output_token_ids=[...e.output_token_ids,s]}async function F(e,s){let t=Object.create(null);for(let n of e.session.inputNames)t[n]=s[n];return e.session.inputNames.includes("token_type_ids")&&!t.token_type_ids&&(t.token_type_ids=new r.qY("int64",new BigInt64Array(t.input_ids.data.length),t.input_ids.dims)),await w(e.session,t)}async function C(e,s){let{input_ids:t,past_key_values:n,attention_mask:a}=s,i={input_ids:t,attention_mask:a??x(e,t)},o=!!n;e.session.inputNames.includes("use_cache_branch")&&(i.use_cache_branch=M(o)),y(e.session,i,o),e.addPastKeyValues(i,n);let r=await w(e.session,i);return{logits:r.logits,past_key_values:n=e.getPastKeyValues(r,n)}}function L(e,s,t,n,a){let i=[],o=0;for(let t of s){let s,r=t.tolist().map(Number);t.dims=[1,...t.dims],a?(s=a[o]).dims=[1,...s.dims]:s=x(e,t);let l={input:t,model_input_ids:t,attention_mask:s,prev_model_outputs:null,output_token_ids:r,num_output_tokens:n,done:!1,score:0,id:o++};i.push(l)}return i}async function A(e,s){let t=new BigInt64Array(s.output_token_ids.length).fill(1n),n={input_ids:s.model_input_ids,attention_mask:new r.qY("int64",t,[1,t.length]),past_key_values:s.prev_model_outputs?.past_key_values},a=await e.forward(n);return s.prev_model_outputs=a,a}function P(e,s){e.output_token_ids=[...e.output_token_ids,s],e.model_input_ids=new r.qY("int64",[BigInt(s)],[1,1])}class q extends a.bV{main_input_name="input_ids";constructor(e,s){super(),this.config=e,this.session=s;let t=g.get(this.constructor),n=m.get(t);this.can_generate=!1,this._runBeam=null,this._getStartBeams=null,this._updateBeam=null,this._forward=null,n===h.DecoderOnly?(this.can_generate=!0,this._runBeam=A,this._getStartBeams=L,this._updateBeam=P,this._forward=C):n===h.Seq2Seq||n===h.Vision2Seq?(this.can_generate=!0,this._runBeam=v,this._getStartBeams=b,this._updateBeam=S,this._forward=k):(h.EncoderDecoder,this._forward=F)}async dispose(){let e=[];for(let s of Object.keys(this)){let t=this[s];t instanceof d&&e.push(t.handler.dispose())}return await Promise.all(e)}static async from_pretrained(e,{quantized:s=!0,progress_callback:t=null,config:a=null,cache_dir:o=null,local_files_only:r=!1,revision:l="main",model_file_name:c=null}={}){let d,_={quantized:s,progress_callback:t,config:a,cache_dir:o,local_files_only:r,revision:l,model_file_name:c},u=g.get(this),p=m.get(u);return p===h.DecoderOnly?d=await Promise.all([n.E.from_pretrained(e,_),f(e,_.model_file_name??"decoder_model_merged",_),(0,i.wc)(e,"generation_config.json",!1,_)]):p===h.Seq2Seq||p===h.Vision2Seq?d=await Promise.all([n.E.from_pretrained(e,_),f(e,"encoder_model",_),f(e,"decoder_model_merged",_),(0,i.wc)(e,"generation_config.json",!1,_)]):p===h.MaskGeneration?d=await Promise.all([n.E.from_pretrained(e,_),f(e,"vision_encoder",_),f(e,"prompt_encoder_mask_decoder",_)]):p===h.EncoderDecoder?d=await Promise.all([n.E.from_pretrained(e,_),f(e,"encoder_model",_),f(e,"decoder_model_merged",_)]):(p!==h.EncoderOnly&&console.warn(`Model type for '${u??a?.model_type}' not found, assuming encoder-only architecture. Please report this at https://github.com/xenova/transformers.js/issues/new/choose.`),d=await Promise.all([n.E.from_pretrained(e,_),f(e,_.model_file_name??"model",_)])),new this(...d)}async _call(e){return await this.forward(e)}async forward(e){return await this._forward(this,e)}_get_logits_processor(e,s,t=null){let n=new o.VT;if(null!==e.repetition_penalty&&1!==e.repetition_penalty&&n.push(new o.hK(e.repetition_penalty)),null!==e.no_repeat_ngram_size&&e.no_repeat_ngram_size>0&&n.push(new o.Y8(e.no_repeat_ngram_size)),null!==e.bad_words_ids&&n.push(new o.SP(e.bad_words_ids,e.eos_token_id)),null!==e.min_length&&null!==e.eos_token_id&&e.min_length>0&&n.push(new o.pe(e.min_length,e.eos_token_id)),null!==e.min_new_tokens&&null!==e.eos_token_id&&e.min_new_tokens>0&&n.push(new o.z_(s,e.min_new_tokens,e.eos_token_id)),null!==e.forced_bos_token_id&&n.push(new o.zM(e.forced_bos_token_id)),null!==e.forced_eos_token_id&&n.push(new o.uB(e.max_length,e.forced_eos_token_id)),null!==e.begin_suppress_tokens){let t=s>1||null===e.forced_bos_token_id?s:s+1;null!==e.forced_decoder_ids&&(t+=e.forced_decoder_ids[e.forced_decoder_ids.length-1][0]),n.push(new o.S3(e.begin_suppress_tokens,t))}return null!==e.forced_decoder_ids&&n.push(new o.kU(e.forced_decoder_ids)),null!==t&&n.extend(t),n}_get_generation_config(e){let s=new o.Fq(this.config);return"generation_config"in this&&Object.assign(s,this.generation_config),null!==e&&Object.assign(s,e),s}async generate(e,s=null,t=null,{inputs_attention_mask:n=null}={}){let i;if(!this.can_generate){let e=g.get(this.constructor),s=`The current model class (${e}) is not compatible with \`.generate()\`, as it doesn't have a language model head.`,t=this.config.model_type,n=aR.get(t)??a$.get(t)??aG.get(t)??aQ.get(t);throw n&&(s+=` Please use the following class instead: '${n[0]}'`),Error(s)}if(!(e instanceof r.qY)&&!(0,a.iu)(e)&&!Array.isArray(e))throw Error(`\`inputs\` must be a Tensor, TypedArray, or Array, but is "${e.constructor.name}".`);if(this.config.is_encoder_decoder)i=0;else if(0===(i=e instanceof r.qY?e.dims.at(-1):e.length))throw Error("Must supply a non-empty array of input token ids.");s=this._get_generation_config(s),t=t??new o.VT,t=this._get_logits_processor(s,i,t);let l=s.eos_token_id;null===l||Array.isArray(l)||(l=[l]);let c=1,d=1+(s.max_new_tokens??1/0),_=Number.isInteger(s.max_length)&&(s.max_new_tokens??null)===null,u=o.LC.getSampler(s),h=this.getStartBeams(e,s,c,n);for(;h.some(e=>!e.done)&&c<d;){let e=[];for(let n of h){if(n.done){e.push(n);continue}if(_&&n.output_token_ids.length>=s.max_length){n.done=!0,e.push(n);continue}let a=await this.runBeam(n);s.output_attentions&&this.addAttentionsToBeam(n,a),s.output_scores;let i=a.logits.slice(null,-1,null);for(let[s,a]of(t(n.output_token_ids,i),u(i))){let t={...n};this.updateBeam(t,s),t.score+=a,l&&l.includes(s)&&(t.done=!0),e.push(t)}}++c,h=(e=this.groupBeams(e).map(e=>e.sort((e,s)=>s.score-e.score).slice(0,s.num_beams))).flat(),s.callback_function&&s.callback_function(h)}let m=this.groupBeams(h),p=e=>m.map(t=>s.num_return_sequences>1?t.slice(0,s.num_return_sequences).map(s=>s[e]):[t[0][e]]).flat(),f=p("output_token_ids");return s.return_dict_in_generate?{sequences:f,decoder_attentions:p("decoder_attentions"),cross_attentions:p("cross_attentions")}:f}addAttentionsToBeam(e,s){if(this.config.is_encoder_decoder){if(!s.cross_attentions||0===s.cross_attentions.length)throw Error("`output_attentions` is true, but the model did not produce cross-attentions. This is most likely because the model was not exported with `output_attentions=True`.");e.cross_attentions||(e.cross_attentions=[]),e.cross_attentions.push(s.cross_attentions)}if(!s.decoder_attentions||0===s.decoder_attentions.length)throw Error("`output_attentions` is true, but the model did not produce decoder-attentions. This is most likely because the model was not exported with `output_attentions=True`.");e.decoder_attentions||(e.decoder_attentions=[]),e.decoder_attentions.push(s.decoder_attentions)}groupBeams(e){let s=Object.create(null);for(let t of e)void 0===s[t.id]?s[t.id]=[t]:s[t.id].push(t);return Object.values(s)}getPastKeyValues(e,s){let t=Object.create(null);for(let n in e)if(n.startsWith("present")){let a=n.replace("present","past_key_values");s&&n.includes("encoder")?t[a]=s[a]:t[a]=e[n]}return t}getAttentions(e){let s=Object.create(null);for(let t of["cross_attentions","decoder_attentions"]){let n=[];for(let s in e)s.startsWith(t)&&(n[s.split(".").pop()]=e[s]);s[t]=n}return s}addPastKeyValues(e,s){if(s)Object.assign(e,s);else if(this.config.is_encoder_decoder&&(this.add_encoder_pkv??!0)){let s=[1,this.num_encoder_heads,0,this.encoder_dim_kv],t=[1,this.num_decoder_heads,0,this.decoder_dim_kv];for(let n=0;n<this.num_decoder_layers;++n)e[`past_key_values.${n}.encoder.key`]=new r.qY("float32",[],s),e[`past_key_values.${n}.encoder.value`]=new r.qY("float32",[],s),e[`past_key_values.${n}.decoder.key`]=new r.qY("float32",[],t),e[`past_key_values.${n}.decoder.value`]=new r.qY("float32",[],t)}else if("falcon"===this.config.model_type){let s=[+this.num_heads,0,this.dim_kv];for(let t=0;t<this.num_layers;++t)e[`past_key_values.${t}.key`]=new r.qY("float32",[],s),e[`past_key_values.${t}.value`]=new r.qY("float32",[],s)}else if(this.config.multi_query){let s=[+this.num_heads,0,2*this.dim_kv];for(let t=0;t<this.num_layers;++t)e[`past_key_values.${t}.key_value`]=new r.qY("float32",[],s)}else if("bloom"===this.config.model_type){let s=[+this.num_heads,this.dim_kv,0],t=[+this.num_heads,0,this.dim_kv];for(let n=0;n<this.num_layers;++n)e[`past_key_values.${n}.key`]=new r.qY("float32",[],s),e[`past_key_values.${n}.value`]=new r.qY("float32",[],t)}else{let s=[1,this.num_heads,0,this.dim_kv];for(let t=0;t<this.num_layers;++t)e[`past_key_values.${t}.key`]=new r.qY("float32",[],s),e[`past_key_values.${t}.value`]=new r.qY("float32",[],s)}}getStartBeams(e,s,t,n){return this._getStartBeams(this,e,s,t,n)}async runBeam(e){return await this._runBeam(this,e)}updateBeam(e,s){return this._updateBeam(e,s)}}class E{}class T extends E{constructor({last_hidden_state:e,hidden_states:s=null,attentions:t=null}){super(),this.last_hidden_state=e,this.hidden_states=s,this.attentions=t}}class D extends q{}class B extends D{}class I extends D{async _call(e){return new iT(await super._call(e))}}class O extends D{async _call(e){return new iP(await super._call(e))}}class N extends D{async _call(e){return new iE(await super._call(e))}}class G extends D{async _call(e){return new iD(await super._call(e))}}class V extends q{}class j extends V{}class z extends q{}class Y extends z{}class $ extends z{async _call(e){return new iT(await super._call(e))}}class R extends z{async _call(e){return new iP(await super._call(e))}}class W extends z{async _call(e){return new iE(await super._call(e))}}class X extends z{async _call(e){return new iD(await super._call(e))}}class Q extends q{}class U extends Q{}class H extends Q{async _call(e){return new iT(await super._call(e))}}class K extends Q{async _call(e){return new iP(await super._call(e))}}class Z extends Q{async _call(e){return new iE(await super._call(e))}}class J extends Q{async _call(e){return new iD(await super._call(e))}}class ee extends q{}class es extends ee{}class et extends ee{async _call(e){return new iT(await super._call(e))}}class en extends ee{async _call(e){return new iP(await super._call(e))}}class ea extends ee{async _call(e){return new iE(await super._call(e))}}class ei extends ee{async _call(e){return new iD(await super._call(e))}}class eo extends q{}class er extends eo{}class el extends eo{async _call(e){return new iT(await super._call(e))}}class ec extends eo{async _call(e){return new iP(await super._call(e))}}class ed extends eo{async _call(e){return new iE(await super._call(e))}}class e_ extends eo{async _call(e){return new iD(await super._call(e))}}class eu extends q{}class eh extends eu{}class em extends eu{async _call(e){return new iT(await super._call(e))}}class ep extends eu{async _call(e){return new iP(await super._call(e))}}class eg extends eu{async _call(e){return new iE(await super._call(e))}}class ef extends eu{async _call(e){return new iD(await super._call(e))}}class ew extends q{}class ex extends ew{}class ey extends ew{async _call(e){return new iT(await super._call(e))}}class eM extends ew{async _call(e){return new iP(await super._call(e))}}class ek extends ew{async _call(e){return new iE(await super._call(e))}}class eb extends ew{async _call(e){return new iD(await super._call(e))}}class ev extends q{}class eS extends ev{}class eF extends ev{async _call(e){return new iP(await super._call(e))}}class eC extends ev{async _call(e){return new iE(await super._call(e))}}class eL extends ev{async _call(e){return new iD(await super._call(e))}}class eA extends ev{async _call(e){return new iT(await super._call(e))}}class eP extends q{}class eq extends eP{}class eE extends eP{async _call(e){return new iT(await super._call(e))}}class eT extends eP{async _call(e){return new iP(await super._call(e))}}class eD extends eP{async _call(e){return new iE(await super._call(e))}}class eB extends q{}class eI extends eB{}class eO extends eB{async _call(e){return new iT(await super._call(e))}}class eN extends eB{async _call(e){return new iP(await super._call(e))}}class eG extends eB{async _call(e){return new iD(await super._call(e))}}class eV extends q{}class ej extends eV{}class ez extends eV{async _call(e){return new iT(await super._call(e))}}class eY extends eV{async _call(e){return new iP(await super._call(e))}}class e$ extends eV{async _call(e){return new iE(await super._call(e))}}class eR extends eV{async _call(e){return new iD(await super._call(e))}}class eW extends q{}class eX extends eW{}class eQ extends eW{async _call(e){return new iT(await super._call(e))}}class eU extends eW{async _call(e){return new iP(await super._call(e))}}class eH extends eW{async _call(e){return new iD(await super._call(e))}}class eK extends q{}class eZ extends eK{}class eJ extends eK{async _call(e){return new iP(await super._call(e))}}class e2 extends eK{async _call(e){return new iD(await super._call(e))}}class e0 extends eK{async _call(e){return new iT(await super._call(e))}}class e1 extends q{}class e3 extends e1{}class e5 extends e1{constructor(e,s,t,n){super(e,s),this.decoder_merged_session=t,this.generation_config=n,this.num_decoder_layers=this.config.num_decoder_layers,this.num_decoder_heads=this.config.num_heads,this.decoder_dim_kv=this.config.d_kv,this.num_encoder_layers=this.config.num_layers,this.num_encoder_heads=this.config.num_heads,this.encoder_dim_kv=this.config.d_kv}}class e4 extends q{}class e6 extends e4{}class e7 extends e4{constructor(e,s,t,n){super(e,s),this.decoder_merged_session=t,this.generation_config=n,this.num_decoder_layers=this.config.num_decoder_layers,this.num_decoder_heads=this.config.num_heads,this.decoder_dim_kv=this.config.d_kv,this.num_encoder_layers=this.config.num_layers,this.num_encoder_heads=this.config.num_heads,this.encoder_dim_kv=this.config.d_kv}}class e8 extends q{}class e9 extends e8{}class se extends e8{constructor(e,s,t,n){super(e,s),this.decoder_merged_session=t,this.generation_config=n,this.num_decoder_layers=this.config.num_decoder_layers,this.num_decoder_heads=this.config.num_heads,this.decoder_dim_kv=this.config.d_kv,this.num_encoder_layers=this.config.num_layers,this.num_encoder_heads=this.config.num_heads,this.encoder_dim_kv=this.config.d_kv}}class ss extends q{}class st extends ss{}class sn extends ss{constructor(e,s,t,n){super(e,s),this.decoder_merged_session=t,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class sa extends ss{async _call(e){return new iP(await super._call(e))}}class si extends q{}class so extends si{}class sr extends si{constructor(e,s,t,n){super(e,s),this.decoder_merged_session=t,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class sl extends si{async _call(e){return new iP(await super._call(e))}}class sc extends si{constructor(e,s,t){super(e,s),this.generation_config=t,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class sd extends q{}class s_ extends sd{}class su extends sd{constructor(e,s,t,n){super(e,s),this.decoder_merged_session=t,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class sh extends q{}class sm extends sh{}class sp extends sh{constructor(e,s,t,n){super(e,s),this.decoder_merged_session=t,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class sg extends q{}class sf extends sg{}class sw extends sg{async _call(e){return new iT(await super._call(e))}}class sx extends sg{async _call(e){return new iP(await super._call(e))}}class sy extends sg{async _call(e){return new iE(await super._call(e))}}class sM extends sg{async _call(e){return new iD(await super._call(e))}}class sk extends q{}class sb extends sk{}class sv extends sk{async _call(e){return new iT(await super._call(e))}}class sS extends sk{async _call(e){return new iP(await super._call(e))}}class sF extends sk{async _call(e){return new iE(await super._call(e))}}class sC extends sk{async _call(e){return new iD(await super._call(e))}}class sL extends q{}class sA extends sL{}class sP extends sL{async _call(e){return new iT(await super._call(e))}}class sq extends sL{async _call(e){return new iP(await super._call(e))}}class sE extends sL{async _call(e){return new iE(await super._call(e))}}class sT extends sL{async _call(e){return new iD(await super._call(e))}}class sD extends q{}class sB extends sD{}class sI extends sD{}class sO extends q{}class sN extends sO{}class sG extends sO{requires_attention_mask=!1;main_input_name="input_features";constructor(e,s,t,n){super(e,s),this.decoder_merged_session=t,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}async generate(e,s=null,t=null){if(s=this._get_generation_config(s),s.return_timestamps??=!1,s.return_timestamps&&(t=[new o.Fg(s)]),s.return_token_timestamps&&(s.output_attentions=!0,s.return_dict_in_generate=!0,"translate"===s.task&&console.warn("Token-level timestamps may not be reliable for task 'translate'."),!s.alignment_heads))throw Error("Model generation config has no `alignment_heads`, token-level timestamps not available. See https://gist.github.com/hollance/42e32852f24243b748ae6bc1f985b13a on how to add this property to the generation config.");let n=await super.generate(e,s,t);return s.return_token_timestamps&&s.alignment_heads&&(n.token_timestamps=this._extract_token_timestamps(n,s.alignment_heads,s.num_frames)),n}_extract_token_timestamps(e,s,t=null,n=.02){if(!e.cross_attentions)throw Error("Model outputs must contain cross attentions to extract timestamps. This is most likely because the model was not exported with `output_attentions=True`.");let i=this.config.median_filter_width;void 0===i&&(console.warn("Model config has no `median_filter_width`, using default value of 7."),i=7);let o=e.cross_attentions.map(e=>{let n=Array.from({length:this.config.decoder_layers},(s,t)=>(0,r.$q)(e.map(e=>e[t]),2)),a=(0,r.t$)(s.map(([e,s])=>t?n[e].slice(null,s,null,[0,t]):n[e].slice(null,s)));a=a.transpose(1,0,2,3);let[o,l]=(0,r.cQ)(a,-2,0,!0),d=a.clone();for(let e=0;e<d.dims[0];++e){let s=d[e];for(let t=0;t<s.dims[0];++t){let n=s[t],a=o[e][t][0],r=l[e][t][0];for(let e=0;e<n.dims[0];++e){let s=n[e];for(let e=0;e<s.data.length;++e)s.data[e]=(s.data[e]-r.data[e])/a.data[e];s.data.set((0,c.medianFilter)(s.data,i))}}}return(0,r.i2)(d,1)}),l=[e.sequences.length,e.sequences[0].length],d=new r.qY("float32",new Float32Array(l[0]*l[1]),l);for(let e=0;e<l[0];++e){let s=o[e].neg().squeeze_(0),[t,i]=(0,r.$y)(s),l=Array.from({length:t.length-1},(e,s)=>t[s+1]-t[s]),c=(0,a.TR)([1],l).map(e=>!!e),_=[];for(let e=0;e<c.length;++e)c[e]&&_.push(i[e]*n);d[e].data.set(_,1)}return d}}class sV extends q{main_input_name="pixel_values";constructor(e,s,t,n){super(e,s),this.decoder_merged_session=t,this.generation_config=n;let a=this.config.encoder,i=this.config.decoder,o=a.model_type;(aI.get(o)??aO.get(o))||console.warn(`Model type for encoder '${o}' not found, assuming encoder-only architecture. Please report this at https://github.com/xenova/transformers.js/issues/new/choose.`);let r=aR.get(i.model_type);if(!r)throw Error(`Unable to construct \`VisionEncoderDecoder\` due to unsupported decoder: "${this.config.decoder.model_type}"`);let l=new r[1](i,t,n);this.add_encoder_pkv="num_decoder_layers"in l,this.add_encoder_pkv?(this.num_decoder_layers=l.num_decoder_layers,this.num_decoder_heads=l.num_decoder_heads,this.decoder_dim_kv=l.decoder_dim_kv,this.num_encoder_layers=l.num_encoder_layers,this.num_encoder_heads=l.num_encoder_heads,this.encoder_dim_kv=l.encoder_dim_kv):(this.num_layers=l.num_layers,this.num_heads=l.num_heads,this.dim_kv=l.dim_kv)}}class sj extends q{}class sz extends sj{}class sY extends sj{static async from_pretrained(e,s={}){return s.model_file_name??="text_model",super.from_pretrained(e,s)}}class s$ extends sj{static async from_pretrained(e,s={}){return s.model_file_name??="vision_model",super.from_pretrained(e,s)}}class sR extends q{}class sW extends sR{}class sX extends sR{static async from_pretrained(e,s={}){return s.model_file_name??="text_model",super.from_pretrained(e,s)}}class sQ extends sj{static async from_pretrained(e,s={}){return s.model_file_name??="vision_model",super.from_pretrained(e,s)}}class sU extends q{}class sH extends sU{}class sK extends q{}class sZ extends sK{}class sJ extends sK{}class s2 extends q{constructor(e,s,t){super(e,s),this.generation_config=t,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}}class s0 extends s2{}class s1 extends s2{}class s3 extends q{constructor(e,s,t){super(e,s),this.generation_config=t,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_heads,this.num_layers=this.config.num_layers,this.dim_kv=this.config.hidden_size/this.num_heads}}class s5 extends s3{}class s4 extends s3{}class s6 extends q{constructor(e,s,t){super(e,s),this.generation_config=t,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}}class s7 extends s6{}class s8 extends s6{}class s9 extends q{constructor(e,s,t){super(e,s),this.generation_config=t,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}}class te extends s9{}class ts extends s9{}class tt extends q{constructor(e,s,t){super(e,s),this.generation_config=t,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}}class tn extends tt{}class ta extends tt{}class ti extends q{constructor(e,s,t){super(e,s),this.generation_config=t,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.n_embd/this.num_heads}}class to extends ti{}class tr extends ti{}class tl extends q{constructor(e,s,t){super(e,s),this.generation_config=t,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_key_value_heads??this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}}class tc extends tl{}class td extends tl{}class t_ extends q{constructor(e,s,t){super(e,s),this.generation_config=t,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_key_value_heads??this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}}class tu extends t_{}class th extends t_{}class tm extends q{constructor(e,s,t){super(e,s),this.generation_config=t,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}}class tp extends tm{}class tg extends tm{}class tf extends q{constructor(e,s,t){super(e,s),this.generation_config=t,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_head,this.num_layers=this.config.n_layer,this.dim_kv=this.config.hidden_size/this.num_heads}}class tw extends tf{}class tx extends tf{}class ty extends q{constructor(e,s,t){super(e,s),this.generation_config=t,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.n_heads,this.num_layers=this.config.n_layers,this.dim_kv=this.config.d_model/this.num_heads}}class tM extends ty{}class tk extends ty{}class tb extends q{constructor(e,s,t){super(e,s),this.generation_config=t,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}}class tv extends tb{}class tS extends tb{}class tF extends q{}class tC extends tF{}class tL extends tF{async _call(e){return new iP(await super._call(e))}}class tA extends q{}class tP extends tA{}class tq extends tA{async _call(e){return new iP(await super._call(e))}}class tE extends q{}class tT extends tE{async _call(e){return new iO(await super._call(e))}}class tD extends q{}class tB extends tD{}class tI extends tD{async _call(e){return new iP(await super._call(e))}}class tO extends q{}class tN extends tO{}class tG extends tO{async _call(e){return new iP(await super._call(e))}}class tV extends q{}class tj extends tV{}class tz extends tV{}class tY extends q{}class t$ extends tY{}class tR extends tY{}class tW extends q{}class tX extends tW{}class tQ extends tW{async _call(e){return new iP(await super._call(e))}}class tU extends q{}class tH extends tU{}class tK extends tU{async _call(e){return new tJ(await super._call(e))}}class tZ extends tU{async _call(e){return new t2(await super._call(e))}}class tJ extends E{constructor({logits:e,pred_boxes:s}){super(),this.logits=e,this.pred_boxes=s}}class t2 extends E{constructor({logits:e,pred_boxes:s,pred_masks:t}){super(),this.logits=e,this.pred_boxes=s,this.pred_masks=t}}class t0 extends q{}class t1 extends t0{}class t3 extends t0{async _call(e){return new t5(await super._call(e))}}class t5 extends tJ{}class t4 extends q{}class t6 extends t4{}class t7 extends t4{async _call(e){return new iP(await super._call(e))}}class t8 extends q{}class t9 extends t8{}class ne extends t8{async _call(e){return new iP(await super._call(e))}}class ns extends q{}class nt extends ns{}class nn extends ns{async _call(e){return new iP(await super._call(e))}}class na extends q{}class ni extends na{}class no extends na{}class nr extends q{}class nl extends nr{}class nc extends nr{}class nd extends q{}class n_ extends nd{}class nu extends q{}class nh extends nu{}class nm extends nu{}class np extends q{}class ng extends np{}class nf extends q{}class nw extends nf{}class nx extends nf{async _call(e){return new iP(await super._call(e))}}class ny extends q{}class nM extends ny{}class nk extends ny{async _call(e){return new iP(await super._call(e))}}class nb extends q{}class nv extends nb{}class nS extends nb{async _call(e){return new iP(await super._call(e))}}class nF extends q{}class nC extends nF{}class nL extends nF{async _call(e){return new nA(await super._call(e))}}class nA extends E{constructor({logits:e,pred_boxes:s}){super(),this.logits=e,this.pred_boxes=s}}class nP extends q{}class nq extends nP{constructor(e,s,t){super(e,s),this.prompt_encoder_mask_decoder=t}async get_image_embeddings({pixel_values:e}){return await F(this,{pixel_values:e})}async forward(e){if(e.image_embeddings&&e.image_positional_embeddings||(e={...e,...await this.get_image_embeddings(e)}),!e.input_labels){let s=e.input_points.dims.slice(0,-1),t=s.reduce((e,s)=>e*s,1);e.input_labels=new r.qY("int64",new BigInt64Array(t).fill(1n),s)}return await w(this.prompt_encoder_mask_decoder,{input_points:e.input_points,input_labels:e.input_labels,image_embeddings:e.image_embeddings,image_positional_embeddings:e.image_positional_embeddings})}async _call(e){return new nE(await super._call(e))}}class nE extends E{constructor({iou_scores:e,pred_masks:s}){super(),this.iou_scores=e,this.pred_masks=s}}class nT extends q{}class nD extends nT{}class nB extends nT{constructor(e,s,t,n){super(e,s),this.decoder_merged_session=t,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class nI extends q{}class nO extends nI{}class nN extends nI{constructor(e,s,t,n){super(e,s),this.decoder_merged_session=t,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.d_model/this.num_encoder_heads}}class nG extends q{}class nV extends nG{}class nj extends nG{async _call(e){return new iB(await super._call(e))}}class nz extends nG{async _call(e){return new iP(await super._call(e))}}class nY extends nG{async _call(e){return new iE(await super._call(e))}}class n$ extends q{}class nR extends n${}class nW extends n${async _call(e){return new iB(await super._call(e))}}class nX extends n${async _call(e){return new iP(await super._call(e))}}class nQ extends q{}class nU extends nQ{}class nH extends nQ{async _call(e){return new iB(await super._call(e))}}class nK extends nQ{async _call(e){return new iP(await super._call(e))}}class nZ extends nQ{async _call(e){return new iE(await super._call(e))}}class nJ extends q{}class n2 extends nJ{}class n0 extends nJ{async _call(e){return new iB(await super._call(e))}}class n1 extends nJ{async _call(e){return new iP(await super._call(e))}}class n3 extends q{}class n5 extends nG{}class n4 extends nG{async _call(e){return new iB(await super._call(e))}}class n6 extends nG{async _call(e){return new iP(await super._call(e))}}class n7 extends q{}class n8 extends n7{}class n9 extends n7{async _call(e){return new iB(await super._call(e))}}class ae extends n7{async _call(e){return new iP(await super._call(e))}}class as extends n7{async _call(e){return new iq(await super._call(e))}}class at extends n7{async _call(e){return new iE(await super._call(e))}}class an extends q{}class aa extends an{}class ai extends an{}class ao extends an{constructor(e,s,t,n){super(e,s),this.decoder_merged_session=t,this.generation_config=n,this.num_decoder_layers=this.config.decoder_layers,this.num_decoder_heads=this.config.decoder_attention_heads,this.decoder_dim_kv=this.config.hidden_size/this.num_decoder_heads,this.num_encoder_layers=this.config.encoder_layers,this.num_encoder_heads=this.config.encoder_attention_heads,this.encoder_dim_kv=this.config.hidden_size/this.num_encoder_heads}async generate_speech(e,s,{threshold:t=.5,minlenratio:n=0,maxlenratio:a=20,vocoder:i=null}={}){let{encoder_outputs:o,encoder_attention_mask:l}=await F(this,{input_ids:e}),c=o.dims[1]/this.config.reduction_factor,d=Math.floor(c*a),_=Math.floor(c*n),u=this.config.num_mel_bins,h=[],m=null,p=null,g=0;for(;;){++g;let e={use_cache_branch:M(!!p),output_sequence:p?p.output_sequence_out:new r.qY("float32",new Float32Array(u),[1,1,u]),encoder_attention_mask:l,speaker_embeddings:s,encoder_hidden_states:o};this.addPastKeyValues(e,m),p=await w(this.decoder_merged_session,e),m=this.getPastKeyValues(p,m);let{prob:n,spectrum:a}=p;if(h.push(a),g>=_&&(Array.from(n.data).filter(e=>e>=t).length>0||g>=d))break}let f=(0,r.$q)(h),{waveform:x}=await w(i.session,{spectrogram:f});return{spectrogram:f,waveform:x}}}class ar extends q{main_input_name="spectrogram"}class al extends q{constructor(e,s,t){super(e,s),this.generation_config=t,this.config.pad_token_id=this.config.eos_token_id,this.num_encoder_layers=this.num_decoder_layers=this.config.decoder_layers,this.num_encoder_heads=this.num_decoder_heads=this.config.decoder_attention_heads,this.encoder_dim_kv=this.decoder_dim_kv=this.config.d_model/this.num_decoder_heads}}class ac extends al{}class ad extends q{constructor(e,s,t){super(e,s),this.generation_config=t,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_key_value_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}}class a_ extends ad{}class au extends ad{}class ah extends q{constructor(e,s,t){super(e,s),this.generation_config=t,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_key_value_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}}class am extends ah{}class ap extends ah{}class ag extends q{constructor(e,s,t){super(e,s),this.generation_config=t,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.config.num_attention_heads}}class af extends ag{}class aw extends ag{}class ax extends q{}class ay extends ax{}class aM extends ax{static async from_pretrained(e,s={}){return s.model_file_name??="text_model",super.from_pretrained(e,s)}}class ak extends ax{static async from_pretrained(e,s={}){return s.model_file_name??="audio_model",super.from_pretrained(e,s)}}class ab extends q{}class av extends ab{async _call(e){return new iN(await super._call(e))}}class aS extends q{}class aF extends aS{}class aC extends aS{}class aL extends aS{}class aA extends q{constructor(e,s,t){super(e,s),this.generation_config=t,this.config.pad_token_id=this.config.eos_token_id,this.num_heads=this.config.num_attention_heads,this.num_layers=this.config.num_hidden_layers,this.dim_kv=this.config.hidden_size/this.num_heads}}class aP extends aA{}class aq extends aA{}class aE extends q{}class aT extends aE{}class aD extends aE{async _call(e){return new iP(await super._call(e))}}class aB{static MODEL_CLASS_MAPPINGS=null;static BASE_IF_FAIL=!1;static async from_pretrained(e,{quantized:s=!0,progress_callback:t=null,config:a=null,cache_dir:i=null,local_files_only:o=!1,revision:r="main",model_file_name:l=null}={}){let c={quantized:s,progress_callback:t,config:a,cache_dir:i,local_files_only:o,revision:r,model_file_name:l};if(a=await n.E.from_pretrained(e,c),c.config||(c.config=a),!this.MODEL_CLASS_MAPPINGS)throw Error("`MODEL_CLASS_MAPPINGS` not implemented for this type of `AutoClass`: "+this.name);for(let s of this.MODEL_CLASS_MAPPINGS){let t=s.get(a.model_type);if(t)return await t[1].from_pretrained(e,c)}if(this.BASE_IF_FAIL)return console.warn(`Unknown model class "${a.model_type}", attempting to construct from base class.`),await q.from_pretrained(e,c);throw Error(`Unsupported model type: ${a.model_type}`)}}let aI=new Map([["bert",["BertModel",B]],["nomic_bert",["NomicBertModel",j]],["roformer",["RoFormerModel",Y]],["electra",["ElectraModel",es]],["esm",["EsmModel",eq]],["convbert",["ConvBertModel",U]],["camembert",["CamembertModel",er]],["deberta",["DebertaModel",eh]],["deberta-v2",["DebertaV2Model",ex]],["mpnet",["MPNetModel",ej]],["albert",["AlbertModel",eZ]],["distilbert",["DistilBertModel",eS]],["roberta",["RobertaModel",sf]],["xlm",["XLMModel",sb]],["xlm-roberta",["XLMRobertaModel",sA]],["clap",["ClapModel",ay]],["clip",["CLIPModel",sz]],["clipseg",["CLIPSegModel",sZ]],["chinese_clip",["ChineseCLIPModel",sH]],["siglip",["SiglipModel",sW]],["mobilebert",["MobileBertModel",eI]],["squeezebert",["SqueezeBertModel",eX]],["wav2vec2",["Wav2Vec2Model",nV]],["wav2vec2-bert",["Wav2Vec2BertModel",n2]],["unispeech",["UniSpeechModel",nR]],["unispeech-sat",["UniSpeechSatModel",nU]],["hubert",["HubertModel",n5]],["wavlm",["WavLMModel",n8]],["audio-spectrogram-transformer",["ASTModel",sB]],["vits",["VitsModel",av]],["detr",["DetrModel",tH]],["table-transformer",["TableTransformerModel",t1]],["vit",["ViTModel",tC]],["fastvit",["FastViTModel",tP]],["mobilevit",["MobileViTModel",tB]],["mobilevitv2",["MobileViTV2Model",tN]],["owlvit",["OwlViTModel",tj]],["owlv2",["Owlv2Model",t$]],["beit",["BeitModel",tX]],["deit",["DeiTModel",t6]],["convnext",["ConvNextModel",nw]],["convnextv2",["ConvNextV2Model",nM]],["dinov2",["Dinov2Model",nv]],["resnet",["ResNetModel",t9]],["swin",["SwinModel",nt]],["swin2sr",["Swin2SRModel",ni]],["donut-swin",["DonutSwinModel",ng]],["yolos",["YolosModel",nC]],["dpt",["DPTModel",nl]],["glpn",["GLPNModel",nh]],["hifigan",["SpeechT5HifiGan",ar]],["efficientnet",["EfficientNetModel",aT]]]),aO=new Map([["t5",["T5Model",e3]],["longt5",["LongT5Model",e6]],["mt5",["MT5Model",e9]],["bart",["BartModel",st]],["mbart",["MBartModel",so]],["marian",["MarianModel",nD]],["whisper",["WhisperModel",sN]],["m2m_100",["M2M100Model",nO]],["blenderbot",["BlenderbotModel",s_]],["blenderbot-small",["BlenderbotSmallModel",sm]]]),aN=new Map([["bloom",["BloomModel",tw]],["gpt2",["GPT2Model",s0]],["gptj",["GPTJModel",te]],["gpt_bigcode",["GPTBigCodeModel",tn]],["gpt_neo",["GPTNeoModel",s5]],["gpt_neox",["GPTNeoXModel",s7]],["codegen",["CodeGenModel",to]],["llama",["LlamaModel",tc]],["qwen2",["Qwen2Model",tu]],["phi",["PhiModel",tp]],["mpt",["MptModel",tM]],["opt",["OPTModel",tv]],["mistral",["MistralModel",a_]],["starcoder2",["Starcoder2Model",am]],["falcon",["FalconModel",af]]]),aG=new Map([["speecht5",["SpeechT5ForSpeechToText",ai]],["whisper",["WhisperForConditionalGeneration",sG]]]),aV=new Map([["speecht5",["SpeechT5ForTextToSpeech",ao]]]),aj=new Map([["vits",["VitsModel",av]]]),az=new Map([["bert",["BertForSequenceClassification",O]],["roformer",["RoFormerForSequenceClassification",R]],["electra",["ElectraForSequenceClassification",en]],["esm",["EsmForSequenceClassification",eT]],["convbert",["ConvBertForSequenceClassification",K]],["camembert",["CamembertForSequenceClassification",ec]],["deberta",["DebertaForSequenceClassification",ep]],["deberta-v2",["DebertaV2ForSequenceClassification",eM]],["mpnet",["MPNetForSequenceClassification",eY]],["albert",["AlbertForSequenceClassification",eJ]],["distilbert",["DistilBertForSequenceClassification",eF]],["roberta",["RobertaForSequenceClassification",sx]],["xlm",["XLMForSequenceClassification",sS]],["xlm-roberta",["XLMRobertaForSequenceClassification",sq]],["bart",["BartForSequenceClassification",sa]],["mbart",["MBartForSequenceClassification",sl]],["mobilebert",["MobileBertForSequenceClassification",eN]],["squeezebert",["SqueezeBertForSequenceClassification",eU]]]),aY=new Map([["bert",["BertForTokenClassification",N]],["roformer",["RoFormerForTokenClassification",W]],["electra",["ElectraForTokenClassification",ea]],["esm",["EsmForTokenClassification",eD]],["convbert",["ConvBertForTokenClassification",Z]],["camembert",["CamembertForTokenClassification",ed]],["deberta",["DebertaForTokenClassification",eg]],["deberta-v2",["DebertaV2ForTokenClassification",ek]],["mpnet",["MPNetForTokenClassification",e$]],["distilbert",["DistilBertForTokenClassification",eC]],["roberta",["RobertaForTokenClassification",sy]],["xlm",["XLMForTokenClassification",sF]],["xlm-roberta",["XLMRobertaForTokenClassification",sE]]]),a$=new Map([["t5",["T5ForConditionalGeneration",e5]],["longt5",["LongT5ForConditionalGeneration",e7]],["mt5",["MT5ForConditionalGeneration",se]],["bart",["BartForConditionalGeneration",sn]],["mbart",["MBartForConditionalGeneration",sr]],["marian",["MarianMTModel",nB]],["m2m_100",["M2M100ForConditionalGeneration",nN]],["blenderbot",["BlenderbotForConditionalGeneration",su]],["blenderbot-small",["BlenderbotSmallForConditionalGeneration",sp]]]),aR=new Map([["bloom",["BloomForCausalLM",tx]],["gpt2",["GPT2LMHeadModel",s1]],["gptj",["GPTJForCausalLM",ts]],["gpt_bigcode",["GPTBigCodeForCausalLM",ta]],["gpt_neo",["GPTNeoForCausalLM",s4]],["gpt_neox",["GPTNeoXForCausalLM",s8]],["codegen",["CodeGenForCausalLM",tr]],["llama",["LlamaForCausalLM",td]],["qwen2",["Qwen2ForCausalLM",th]],["phi",["PhiForCausalLM",tg]],["mpt",["MptForCausalLM",tk]],["opt",["OPTForCausalLM",tS]],["mbart",["MBartForCausalLM",sc]],["mistral",["MistralForCausalLM",au]],["starcoder2",["Starcoder2ForCausalLM",ap]],["falcon",["FalconForCausalLM",aw]],["trocr",["TrOCRForCausalLM",ac]],["stablelm",["StableLmForCausalLM",aq]]]),aW=new Map([["bert",["BertForMaskedLM",I]],["roformer",["RoFormerForMaskedLM",$]],["electra",["ElectraForMaskedLM",et]],["esm",["EsmForMaskedLM",eE]],["convbert",["ConvBertForMaskedLM",H]],["camembert",["CamembertForMaskedLM",el]],["deberta",["DebertaForMaskedLM",em]],["deberta-v2",["DebertaV2ForMaskedLM",ey]],["mpnet",["MPNetForMaskedLM",ez]],["albert",["AlbertForMaskedLM",e0]],["distilbert",["DistilBertForMaskedLM",eA]],["roberta",["RobertaForMaskedLM",sw]],["xlm",["XLMWithLMHeadModel",sv]],["xlm-roberta",["XLMRobertaForMaskedLM",sP]],["mobilebert",["MobileBertForMaskedLM",eO]],["squeezebert",["SqueezeBertForMaskedLM",eQ]]]),aX=new Map([["bert",["BertForQuestionAnswering",G]],["roformer",["RoFormerForQuestionAnswering",X]],["electra",["ElectraForQuestionAnswering",ei]],["convbert",["ConvBertForQuestionAnswering",J]],["camembert",["CamembertForQuestionAnswering",e_]],["deberta",["DebertaForQuestionAnswering",ef]],["deberta-v2",["DebertaV2ForQuestionAnswering",eb]],["mpnet",["MPNetForQuestionAnswering",eR]],["albert",["AlbertForQuestionAnswering",e2]],["distilbert",["DistilBertForQuestionAnswering",eL]],["roberta",["RobertaForQuestionAnswering",sM]],["xlm",["XLMForQuestionAnswering",sC]],["xlm-roberta",["XLMRobertaForQuestionAnswering",sT]],["mobilebert",["MobileBertForQuestionAnswering",eG]],["squeezebert",["SqueezeBertForQuestionAnswering",eH]]]),aQ=new Map([["vision-encoder-decoder",["VisionEncoderDecoderModel",sV]]]),aU=new Map([["vision-encoder-decoder",["VisionEncoderDecoderModel",sV]]]),aH=new Map([["vit",["ViTForImageClassification",tL]],["fastvit",["FastViTForImageClassification",tq]],["mobilevit",["MobileViTForImageClassification",tI]],["mobilevitv2",["MobileViTV2ForImageClassification",tG]],["beit",["BeitForImageClassification",tQ]],["deit",["DeiTForImageClassification",t7]],["convnext",["ConvNextForImageClassification",nx]],["convnextv2",["ConvNextV2ForImageClassification",nk]],["dinov2",["Dinov2ForImageClassification",nS]],["resnet",["ResNetForImageClassification",ne]],["swin",["SwinForImageClassification",nn]],["segformer",["SegformerForImageClassification",aC]],["efficientnet",["EfficientNetForImageClassification",aD]]]),aK=new Map([["detr",["DetrForObjectDetection",tK]],["table-transformer",["TableTransformerForObjectDetection",t3]],["yolos",["YolosForObjectDetection",nL]]]),aZ=new Map([["owlvit",["OwlViTForObjectDetection",tz]],["owlv2",["Owlv2ForObjectDetection",tR]]]),aJ=new Map([["detr",["DetrForSegmentation",tZ]],["clipseg",["CLIPSegForImageSegmentation",sJ]]]),a2=new Map([["segformer",["SegformerForSemanticSegmentation",aL]]]),a0=new Map([["sam",["SamModel",nq]]]),a1=new Map([["wav2vec2",["Wav2Vec2ForCTC",nj]],["wav2vec2-bert",["Wav2Vec2BertForCTC",n0]],["unispeech",["UniSpeechForCTC",nW]],["unispeech-sat",["UniSpeechSatForCTC",nH]],["wavlm",["WavLMForCTC",n9]],["hubert",["HubertForCTC",n4]]]),a3=new Map([["wav2vec2",["Wav2Vec2ForSequenceClassification",nz]],["wav2vec2-bert",["Wav2Vec2BertForSequenceClassification",n1]],["unispeech",["UniSpeechForSequenceClassification",nX]],["unispeech-sat",["UniSpeechSatForSequenceClassification",nK]],["wavlm",["WavLMForSequenceClassification",ae]],["hubert",["HubertForSequenceClassification",n6]],["audio-spectrogram-transformer",["ASTForAudioClassification",sI]]]),a5=new Map([["wavlm",["WavLMForXVector",as]]]),a4=new Map([["unispeech-sat",["UniSpeechSatForAudioFrameClassification",nZ]],["wavlm",["WavLMForAudioFrameClassification",at]],["wav2vec2",["Wav2Vec2ForAudioFrameClassification",nY]]]),a6=new Map([["vitmatte",["VitMatteForImageMatting",tT]]]),a7=new Map([["swin2sr",["Swin2SRForImageSuperResolution",no]]]),a8=new Map([["dpt",["DPTForDepthEstimation",nc]],["depth_anything",["DepthAnythingForDepthEstimation",n_]],["glpn",["GLPNForDepthEstimation",nm]]]),a9=new Map([["clip",["CLIPVisionModelWithProjection",s$]],["siglip",["SiglipVisionModel",sQ]]]),ie=[[aI,h.EncoderOnly],[aO,h.EncoderDecoder],[aN,h.DecoderOnly],[az,h.EncoderOnly],[aY,h.EncoderOnly],[a$,h.Seq2Seq],[aG,h.Seq2Seq],[aR,h.DecoderOnly],[aW,h.EncoderOnly],[aX,h.EncoderOnly],[aQ,h.Vision2Seq],[aH,h.EncoderOnly],[aJ,h.EncoderOnly],[a2,h.EncoderOnly],[a6,h.EncoderOnly],[a7,h.EncoderOnly],[a8,h.EncoderOnly],[aK,h.EncoderOnly],[aZ,h.EncoderOnly],[a0,h.MaskGeneration],[a1,h.EncoderOnly],[a3,h.EncoderOnly],[aV,h.Seq2Seq],[aj,h.EncoderOnly],[a5,h.EncoderOnly],[a4,h.EncoderOnly],[a9,h.EncoderOnly]];for(let[e,s]of ie)for(let[t,n]of e.values())m.set(t,s),g.set(n,t),p.set(t,n);for(let[e,s,t]of[["CLIPTextModelWithProjection",sY,h.EncoderOnly],["SiglipTextModel",sX,h.EncoderOnly],["ClapTextModelWithProjection",aM,h.EncoderOnly],["ClapAudioModelWithProjection",ak,h.EncoderOnly]])m.set(e,t),g.set(s,e),p.set(e,s);class is extends aB{static MODEL_CLASS_MAPPINGS=ie.map(e=>e[0]);static BASE_IF_FAIL=!0}class it extends aB{static MODEL_CLASS_MAPPINGS=[az]}class ia extends aB{static MODEL_CLASS_MAPPINGS=[aY]}class ii extends aB{static MODEL_CLASS_MAPPINGS=[a$]}class io extends aB{static MODEL_CLASS_MAPPINGS=[aG]}class ir extends aB{static MODEL_CLASS_MAPPINGS=[aV]}class il extends aB{static MODEL_CLASS_MAPPINGS=[aj]}class ic extends aB{static MODEL_CLASS_MAPPINGS=[aR]}class id extends aB{static MODEL_CLASS_MAPPINGS=[aW]}class i_ extends aB{static MODEL_CLASS_MAPPINGS=[aX]}class iu extends aB{static MODEL_CLASS_MAPPINGS=[aQ]}class ih extends aB{static MODEL_CLASS_MAPPINGS=[aH]}class im extends aB{static MODEL_CLASS_MAPPINGS=[aJ]}class ip extends aB{static MODEL_CLASS_MAPPINGS=[a2]}class ig extends aB{static MODEL_CLASS_MAPPINGS=[aK]}class iw extends aB{static MODEL_CLASS_MAPPINGS=[aZ]}class ix extends aB{static MODEL_CLASS_MAPPINGS=[a0]}class iy extends aB{static MODEL_CLASS_MAPPINGS=[a1]}class iM extends aB{static MODEL_CLASS_MAPPINGS=[a3]}class ik extends aB{static MODEL_CLASS_MAPPINGS=[a5]}class ib extends aB{static MODEL_CLASS_MAPPINGS=[a4]}class iv extends aB{static MODEL_CLASS_MAPPINGS=[aU]}class iS extends aB{static MODEL_CLASS_MAPPINGS=[a6]}class iF extends aB{static MODEL_CLASS_MAPPINGS=[a7]}class iC extends aB{static MODEL_CLASS_MAPPINGS=[a8]}class iL extends aB{static MODEL_CLASS_MAPPINGS=[a9]}class iA extends E{constructor({logits:e,past_key_values:s,encoder_outputs:t,decoder_attentions:n=null,cross_attentions:a=null}){super(),this.logits=e,this.past_key_values=s,this.encoder_outputs=t,this.decoder_attentions=n,this.cross_attentions=a}}class iP extends E{constructor({logits:e}){super(),this.logits=e}}class iq extends E{constructor({logits:e,embeddings:s}){super(),this.logits=e,this.embeddings=s}}class iE extends E{constructor({logits:e}){super(),this.logits=e}}class iT extends E{constructor({logits:e}){super(),this.logits=e}}class iD extends E{constructor({start_logits:e,end_logits:s}){super(),this.start_logits=e,this.end_logits=s}}class iB extends E{constructor({logits:e}){super(),this.logits=e}}class iI extends E{constructor({logits:e,past_key_values:s}){super(),this.logits=e,this.past_key_values=s}}class iO extends E{constructor({alphas:e}){super(),this.alphas=e}}class iN extends E{constructor({waveform:e,spectrogram:s}){super(),this.waveform=e,this.spectrogram=s}}}}]);